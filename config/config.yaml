# DHG-LGB Configuration File
# All hyperparameters and paths for reproducibility

# ============================================================================
# Data Paths
# ============================================================================
data:
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  embeddings_dir: "data/embeddings"
  results_dir: "results"

  # Raw data files
  diseases_file: "data/raw/diseases.txt"
  nodes_file: "data/raw/nodes.txt"
  associations_file: "data/raw/associations.txt"
  metabolites_smiles_file: "data/raw/metabolites_smiles.txt"
  proteins_fasta_file: "data/raw/proteins.fasta"
  go_ancestors_file: "data/raw/go_ancestors.txt"

# ============================================================================
# Dataset Statistics (from HMDB 5.0 and CTD 2023)
# ============================================================================
dataset:
  n_diseases: 178
  n_metabolites: 2006
  n_proteins: 4912
  n_go_terms: 12524
  n_total_nodes: 19442  # metabolites + proteins + GO terms
  n_positive_samples: 4000  # known metabolite-disease associations

# ============================================================================
# Preprocessing Parameters
# ============================================================================
preprocessing:
  # Negative sampling
  negative_sampling:
    ratio: 1.0  # negative:positive ratio (1:1 for balanced dataset)
    filter_indirect_associations: true  # exclude pairs sharing proteins
    random_seed: 42

  # Similarity matrix computation
  similarity:
    # Metabolite similarity (Tanimoto coefficient)
    metabolite:
      method: "tanimoto"
      fingerprint: "morgan"  # Morgan fingerprints
      radius: 2
      n_bits: 2048

    # Protein similarity (BLAST)
    protein:
      method: "blast"
      program: "blastp"
      version: "2.13.0"
      matrix: "BLOSUM62"
      gap_open: 11
      gap_extend: 1
      evalue_threshold: 10.0
      normalize: true  # normalize to [0, 1]

    # GO semantic similarity
    go:
      method: "ancestral_contribution"
      normalize: true  # naturally [0, 1]

  # Feature extraction
  feature_extraction:
    autoencoder:
      hidden_dims: [1024, 512, 500]  # reduce to 500-D
      activation: "relu"
      dropout: 0.2
      epochs: 100
      batch_size: 128
      learning_rate: 0.001

# ============================================================================
# Hypergraph Neural Network (HGNN) Parameters
# ============================================================================
hgnn:
  # Architecture
  num_layers: 2  # captures 2-hop neighborhood
  embedding_dim: 500  # unified embedding dimension
  hidden_dims: [500, 500]  # dimensions for each layer

  # Regularization
  dropout: 0.4  # stochastic edge sampling
  weight_decay: 5.0e-5  # L2 regularization

  # Training
  optimizer: "adam"
  learning_rate: 0.001
  betas: [0.9, 0.999]
  epochs: 200
  batch_size: 256

  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 1.0e-4
    validation_split: 0.2

  # Message passing
  aggregation: "mean"  # v2e, e2v aggregation method

  # Device
  device: "cuda"  # "cuda" or "cpu"

# ============================================================================
# LightGBM Classifier Parameters
# ============================================================================
classifier:
  algorithm: "lightgbm"

  # Model parameters
  objective: "binary"
  metric: ["auc", "binary_logloss"]
  boosting_type: "gbdt"  # gradient boosting decision tree

  # Tree parameters
  num_leaves: 31
  max_depth: -1  # no limit
  min_data_in_leaf: 20

  # Learning parameters
  learning_rate: 0.1
  n_estimators: 100

  # Regularization
  reg_alpha: 0.0  # L1 regularization
  reg_lambda: 0.1  # L2 regularization
  min_gain_to_split: 0.0

  # Sampling
  bagging_fraction: 1.0
  bagging_freq: 0
  feature_fraction: 1.0

  # Other
  random_state: 42
  n_jobs: -1  # use all CPUs
  verbosity: -1

# ============================================================================
# Cross-Validation Parameters
# ============================================================================
cross_validation:
  method: "kfold"
  n_folds: 5  # 5-fold cross-validation as per paper
  shuffle: true
  random_state: 42

  # Metrics to compute
  metrics:
    - "accuracy"
    - "sensitivity"  # recall
    - "specificity"
    - "precision"
    - "mcc"  # Matthews Correlation Coefficient (most important)
    - "auc"  # Area Under ROC Curve
    - "auprc"  # Area Under Precision-Recall Curve
    - "f1_score"

  # Confidence intervals
  compute_ci: true
  ci_level: 0.95

# ============================================================================
# Evaluation Parameters
# ============================================================================
evaluation:
  # Threshold for binary classification
  decision_threshold: 0.5

  # ROC and PRC curve
  save_curves: true
  n_thresholds: 100

  # Statistical tests
  statistical_tests:
    enabled: true
    methods: ["t-test", "wilcoxon"]
    significance_level: 0.05

# ============================================================================
# Visualization Parameters
# ============================================================================
visualization:
  # Hypergraph visualization
  hypergraph:
    max_nodes_display: 50  # for readability
    node_size_scale: 100
    edge_alpha: 0.6
    color_scheme:
      metabolites: "#4A90E2"  # blue
      proteins: "#50C878"  # green
      go_terms: "#FFB347"  # orange
      diseases: "#FF6B6B"  # red
    layout: "spring"

  # Performance plots
  plots:
    dpi: 300
    format: "png"
    font_size: 12
    figure_size: [10, 6]

# ============================================================================
# Logging Configuration
# ============================================================================
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  save_to_file: true
  log_dir: "results/logs"

# ============================================================================
# Random Seeds (for reproducibility)
# ============================================================================
random_seed: 42
torch_seed: 42
numpy_seed: 42
